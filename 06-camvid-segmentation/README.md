
# 專案 06：CamVid 多類別語意分割 總結

## 專案目標
本專案是整個學習計畫的**畢業專案**，目標是挑戰一個進階的、**多類別的語意分割**任務。這次的挑戰不僅是訓練一個模型，更是要整合先前所有階段學到的技能，包括：處理一種全新的資料標註格式、修改並應用複雜的模型架構 (U-Net)，以及搭建一個完整的端到端訓練與驗證流程。

## 使用資料集
* **名稱**: CamVid (Cambridge-driving Labeled Video Database)
* **任務類型**: 包含 32 個類別的多類別語意分割。
* **關鍵標註格式**: **彩色的 RGB 標籤遮罩 (Colorful RGB Label Masks)**。這是一種對人類視覺友好，但需要進行深度處理才能用於模型訓練的格式。每個獨特的顏色都對應一個特定的類別（如道路、建築、行人等）。

## 我學到的關鍵技術

1.  **進階遮罩處理 (Advanced Mask Processing)**：
    * 這是本次專案最核心的技術突破。我深刻理解了模型與損失函數需要的**索引圖 (Index Map)**（其中每個像素的值是 `0, 1, 2...` 這樣的類別 ID）與資料集提供的**彩色圖**之間的區別。
    * 我成功地從 `class_dict.csv` 建立了「顏色到ID」的映射字典，並用 NumPy 實作了一個高效的 `RGB -> Index Map` 轉換函式，親手打通了資料處理中最關鍵的一環。
    * 我還學會了反向操作，將模型預測出的索引圖，轉換回彩色圖以便於視覺化評估。

2.  **`Dataset` 類別的最終掌握**:
    * 我成功地將這次最複雜的「RGB轉索引圖」邏輯，無縫整合到了 `CamVidDataset` 的 `__getitem__` 方法中，實現了資料的即時預處理。
    * 在這個過程中，我**獨立偵錯並解決了**多次 `FileNotFoundError`，透過分析檔名規律，掌握了處理複雜資料路徑與檔名配對的實用技巧，偵錯能力得到了極大的鍛鍊。

3.  **模型的靈活適應**:
    * 我將先前從零搭建的 U-Net 模型，靈活地應用到了這個新任務上。我學會了如何根據新的資料特性（RGB 輸入, 32 類輸出），正確地修改模型初始化參數 (`n_channels=3`, `n_classes=32`)。

4.  **多類別損失函數的應用**:
    * 我理解了為什麼 `BCEWithLogitsLoss` 適用於二元任務，而**`nn.CrossEntropyLoss`** 才是多類別分割的標準選擇，並成功將其應用在訓練流程中。

## 最終成果
* 我成功地從零開始，搭建並訓練了一個完整的多類別語意分割管道。
* 模型的訓練過程是成功的，驗證集損失 (Validation Loss) 在 20 個 Epochs 的訓練中呈現清晰的下降趨勢，證明了模型的有效學習。
* 我成功地將模型的預測結果視覺化，透過對比「原始影像」、「真實遮罩」和「預測遮罩」，直觀地驗證了整個流程的正確性。

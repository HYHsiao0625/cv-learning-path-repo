# 第三階段：影像分割 (Image Segmentation) 總結

## 專案目標
這個階段的核心目標是掌握比物件偵測更精細的**影像分割**技術。我挑戰了經典的 **TGS Salt Identification** 專案，目標是從零開始，學習並實作一個能夠達到**像素級 (pixel-level)** 理解的 U-Net 模型，不僅要辨識出圖片中是否有鹽體，更要精確地描繪出它們的完整輪廓。

## 使用資料集
* **名稱**: TGS Salt Identification Challenge (Kaggle)
* **任務類型**: **二元語意分割 (Binary Semantic Segmentation)**，即將圖片中的每個像素分類為「鹽體」或「背景」。
* **標註格式**: 成對的影像與**遮罩 (Mask)** 檔案。遮罩是一張黑白圖片，其中像素值 `0` 代表背景，`255` 代表鹽體。

## 我學到的關鍵技術

1.  **U-Net 架構的深刻理解與實作**:
    * 我學習了經典的**編碼器-解碼器 (Encoder-Decoder)** 架構原理。
    * 我理解了 U-Net 的靈魂——**跳躍連接 (Skip Connections)**，如何將編碼器的高解析度空間資訊，與解碼器的高階語意資訊融合，以達成精準的像素定位。
    * 我成功地在 PyTorch 中，從頭搭建了包含 `DoubleConv`, `Down`, `Up` 等模組的完整 U-Net 模型。

2.  **影像分割的資料處理流程**:
    * 我再次應用並鞏固了**客製化 `Dataset`** 的能力，這次是為了處理成對的影像和遮罩檔案。
    * 我學習並導入了一個專業級的資料增強函式庫 **`Albumentations`**。掌握了它如何確保對影像的隨機轉換（如翻轉、旋轉）也能**同步、一致地**應用在遮罩上，這解決了分割任務中資料增強的一大痛點。

3.  **分割模型的訓練與評估**:
    * 我學習了適用於分割任務（特別是類別不平衡場景）的**損失函數**，如 `BCEWithLogitsLoss` 以及 Dice Loss 的概念。
    * 我掌握了影像分割的核心評估指標，如 **IoU** 和 **Dice 係數**，並成功將 Dice 係數的計算整合到我的驗證迴圈中，以即時監控模型表現。

4.  **模型優化的實戰流程**:
    * 這是我在這個階段最大的收穫之一。我完整地經歷了一次專業的**模型優化迭代**：
        1.  **建立基準 (Establishing a Baseline)**：先用簡單的設定訓練 5 個 Epochs，得到約 75% 的 Dice 分數作為基準。
        2.  **分析與假設**: 透過視覺化預測結果，我發現了模型的不足之處，並假設增加訓練時間和資料多樣性可以提升效果。
        3.  **系統性優化**: 我成功地透過**增加訓練週期**和**導入 Albumentations 強力資料增強**兩種手段，將模型的最終表現提升至 **85.41%** 的 Dice 分數。

## 最終成果
我成功地建立、訓練並優化了一個 U-Net 模型。透過系統性的優化實驗，模型的**驗證集 Dice 分數從 75.2% 提升至 85.41%**，這不僅是一個數字上的提升，更代表我已經具備了分析模型瓶頸並尋找解決方案的實踐能力。
